# GPU Configuration
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024
OLLAMA_HOST=0.0.0.0:11434
OLLAMA_ORIGINS=*
OLLAMA_MAX_LOADED_MODELS=3
OLLAMA_NUM_PARALLEL=8
OLLAMA_MAX_QUEUE=1024

# Performance Settings
OLLAMA_TIMEOUT=600
OLLAMA_MAX_RETRIES=3
MODEL_TEMPERATURE=0.3
MAX_TOKENS=32000
BATCH_SIZE=4

# RunPod Paths
RUNPOD_WORKSPACE=/workspace
OUTPUT_DIRECTORY=/workspace/output
DATA_DIRECTORY=/workspace/data
LOG_DIRECTORY=/workspace/logs

# Development Settings
LOG_LEVEL=INFO
ENABLE_MODEL_CACHING=true
CACHE_SIZE_GB=8
ENABLE_GPU_MEMORY_OPTIMIZATION=true

# Ollama Settings
OLLAMA_BASE_URL=http://localhost:11434

# Debug Settings
ENABLE_DEBUG=false
ENABLE_METRICS=true 